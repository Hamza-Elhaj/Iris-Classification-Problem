{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from pandas.plotting import parallel_coordinates\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load through url\n",
    "url = 'http://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data'\n",
    "attributes = [\"sepal_length\", \"sepal_width\", \"petal_length\", \"petal_width\", \"class\"]\n",
    "df = pd.read_csv(url, names = attributes)\n",
    "df.columns = attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load through the file on your desktop\n",
    "df = pd.read_csv('data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Descriptive Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# types for the columns\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# numerical summary, only applies to numerical columns\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of instances in each class\n",
    "df.groupby('species').size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take out a test set\n",
    "train, test = train_test_split(df, test_size = 0.4, stratify = df['species'], random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of instances in each class in training data\n",
    "train.groupby('species').size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Vizualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# histograms\n",
    "n_bins = 10\n",
    "fig, axs = plt.subplots(2, 2)\n",
    "axs[0,0].hist(train['sepal_length'], bins = n_bins);\n",
    "axs[0,0].set_title('Sepal Length');\n",
    "axs[0,1].hist(train['sepal_width'], bins = n_bins);\n",
    "axs[0,1].set_title('Sepal Width');\n",
    "axs[1,0].hist(train['petal_length'], bins = n_bins);\n",
    "axs[1,0].set_title('Petal Length');\n",
    "axs[1,1].hist(train['petal_width'], bins = n_bins);\n",
    "axs[1,1].set_title('Petal Width');\n",
    "\n",
    "# add some spacing between subplots\n",
    "fig.tight_layout(pad=1.0);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# boxplots using seaborn\n",
    "fig, axs = plt.subplots(2, 2)\n",
    "fn = [\"sepal_length\", \"sepal_width\", \"petal_length\", \"petal_width\"]\n",
    "cn = ['setosa', 'versicolor', 'virginica']\n",
    "sns.boxplot(x = 'species', y = 'sepal_length', data = train, order = cn, ax = axs[0,0]);\n",
    "sns.boxplot(x = 'species', y = 'sepal_width', data = train, order = cn, ax = axs[0,1]);\n",
    "sns.boxplot(x = 'species', y = 'petal_length', data = train, order = cn, ax = axs[1,0]);\n",
    "sns.boxplot(x = 'species', y = 'petal_width', data = train,  order = cn, ax = axs[1,1]);\n",
    "# add some spacing between subplots\n",
    "fig.tight_layout(pad=1.0);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# right off the bat, we see that petal length/width can separate setosa from the others\n",
    "# histogram by species\n",
    "setosa_pl = train.loc[df.species=='setosa', 'petal_length']\n",
    "versicolor_pl = train.loc[df.species=='versicolor', 'petal_length']\n",
    "virginica_pl = train.loc[df.species=='virginica', 'petal_length']\n",
    "setosa_pw = train.loc[df.species=='setosa', 'petal_width']\n",
    "versicolor_pw = train.loc[df.species=='versicolor', 'petal_width']\n",
    "virginica_pw = train.loc[df.species=='virginica', 'petal_width']\n",
    "\n",
    "fig, axs = plt.subplots(1, 2)\n",
    "# set figure size\n",
    "fig.set_size_inches(10,4)\n",
    "ax1 = sns.distplot(setosa_pl, color=\"blue\", label=\"Setosa\", ax = axs[0]);\n",
    "ax1.set_title('Petal Length By Species')\n",
    "ax1 = sns.distplot(versicolor_pl, color=\"red\", label=\"Versicolor\", ax = axs[0]);\n",
    "ax1 = sns.distplot(virginica_pl, color=\"green\", label=\"Virginica\", ax = axs[0]);\n",
    "\n",
    "ax2 = sns.distplot(setosa_pw, color=\"blue\", label=\"Setosa\", ax = axs[1]);\n",
    "ax2.set_title('Petal Width By Species')\n",
    "ax2 = sns.distplot(versicolor_pw, color=\"red\", label=\"Versicolor\", ax = axs[1]);\n",
    "ax2 = sns.distplot(virginica_pw, color=\"green\", label=\"Virginica\", ax = axs[1]);\n",
    "\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.violinplot(x=\"species\", y=\"petal_length\", data=train, size=5, order = cn, palette = 'colorblind');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bivariate relationship\n",
    "# scatterplot matrix\n",
    "sns.pairplot(train, hue=\"species\", height = 2, palette = 'colorblind');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# correlation matrix\n",
    "corrmat = train.corr()\n",
    "sns.heatmap(corrmat, annot = True, square = True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parallel coordinates\n",
    "parallel_coordinates(train, \"species\", color = ['blue', 'red', 'green']);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model development"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train[['sepal_length','sepal_width','petal_length','petal_width']]\n",
    "y_train = train.species\n",
    "X_test = test[['sepal_length','sepal_width','petal_length','petal_width']]\n",
    "y_test = test.species"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod_lr = LogisticRegression(solver = 'newton-cg').fit(X_train, y_train)\n",
    "prediction=mod_lr.predict(X_test)\n",
    "print('The accuracy of the Logistic Regression is',\"{:.3f}\".format(metrics.accuracy_score(prediction,y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first try decision tree\n",
    "mod_dt = DecisionTreeClassifier(max_depth = 3, random_state = 1)\n",
    "mod_dt.fit(X_train,y_train)\n",
    "prediction=mod_dt.predict(X_test)\n",
    "print('The accuracy of the Decision Tree is',\"{:.3f}\".format(metrics.accuracy_score(prediction,y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod_dt.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set figure size\n",
    "plt.figure(figsize = (10,8))\n",
    "plot_tree(mod_dt, feature_names = fn, class_names = cn, filled = True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot decision boundary for pedal width vs pedal length\n",
    "plot_step = 0.01\n",
    "plot_colors = \"ryb\"\n",
    "xx, yy = np.meshgrid(np.arange(0, 7, plot_step), np.arange(0, 3, plot_step))\n",
    "plt.tight_layout(h_pad=1, w_pad=1, pad=2.5)\n",
    "\n",
    "selected_predictors = [\"petal_length\", \"petal_width\"]\n",
    "mod_dt_1 = DecisionTreeClassifier(max_depth = 3, random_state = 1)\n",
    "y_train_en = y_train.replace({'setosa':0,'versicolor':1,'virginica':2}).copy()\n",
    "mod_dt_1.fit(X_train[selected_predictors],y_train_en)\n",
    "\n",
    "pred_all = mod_dt_1.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "pred_all = pred_all.reshape(xx.shape)\n",
    "\n",
    "graph = plt.contourf(xx, yy, pred_all, cmap=plt.cm.RdYlBu)\n",
    "\n",
    "plt.xlabel(selected_predictors[0])\n",
    "plt.ylabel(selected_predictors[1])\n",
    "\n",
    "# plot test data points\n",
    "n_class = 3\n",
    "for i, color in zip(cn, plot_colors):\n",
    "    temp = np.where(y_test == i)\n",
    "    idx = [elem for elems in temp for elem in elems]\n",
    "    plt.scatter(X_test.iloc[idx, 2], X_test.iloc[idx, 3], c=color, \n",
    "                label=y_test, cmap=plt.cm.RdYlBu, edgecolor='black', s=20)\n",
    "\n",
    "plt.suptitle(\"Decision Boundary Shown in 2D with Test Data\")\n",
    "plt.axis(\"tight\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# confusion matrix\n",
    "# one versicolor misclassified\n",
    "disp = metrics.plot_confusion_matrix(mod_dt, X_test, y_test,\n",
    "                                 display_labels=cn,\n",
    "                                 cmap=plt.cm.Blues,\n",
    "                                 normalize=None)\n",
    "disp.ax_.set_title('Decision Tree Confusion matrix, without normalization');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guassian Naive Bayes Classifier\n",
    "mod_gnb_all = GaussianNB()\n",
    "y_pred = mod_gnb_all.fit(X_train, y_train).predict(X_test)\n",
    "print('The accuracy of the Guassian Naive Bayes Classifier on test data is',\"{:.3f}\".format(metrics.accuracy_score(y_pred,y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guassian Naive Bayes Classifier with two predictors\n",
    "mod_gnb = GaussianNB()\n",
    "y_pred = mod_gnb.fit(X_train[selected_predictors], y_train).predict(X_test[selected_predictors])\n",
    "print('The accuracy of the Guassian Naive Bayes Classifier with 2 predictors on test data is',\"{:.3f}\".format(metrics.accuracy_score(y_pred,y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Discriminant Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LDA Classifier\n",
    "mod_lda_all = LinearDiscriminantAnalysis()\n",
    "y_pred = mod_lda_all.fit(X_train, y_train).predict(X_test)\n",
    "print('The accuracy of the LDA Classifier on test data is',\"{:.3f}\".format(metrics.accuracy_score(y_pred,y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LDA Classifier with two predictors\n",
    "mod_lda = LinearDiscriminantAnalysis()\n",
    "y_pred = mod_lda.fit(X_train[selected_predictors], y_train).predict(X_test[selected_predictors])\n",
    "print('The accuracy of the LDA Classifier with two predictors on test data is',\"{:.3f}\".format(metrics.accuracy_score(y_pred,y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LDA with 2 predictors\n",
    "mod_lda_1 = LinearDiscriminantAnalysis()\n",
    "y_pred = mod_lda_1.fit(X_train[selected_predictors], y_train_en).predict(X_test[selected_predictors])\n",
    "\n",
    "N = 300\n",
    "X = np.linspace(0, 7, N)\n",
    "Y = np.linspace(0, 3, N)\n",
    "X, Y = np.meshgrid(X, Y)\n",
    "\n",
    "g = sns.FacetGrid(test, hue=\"species\", height=5, palette = 'colorblind').map(plt.scatter,\"petal_length\", \"petal_width\", ).add_legend()\n",
    "my_ax = g.ax\n",
    "\n",
    "zz = np.array([mod_lda_1.predict(np.array([[xx,yy]])) for xx, yy in zip(np.ravel(X), np.ravel(Y)) ] )\n",
    "Z = zz.reshape(X.shape)\n",
    "\n",
    "#Plot the filled and boundary contours\n",
    "my_ax.contourf( X, Y, Z, 2, alpha = .1, colors = ('blue','green','red'))\n",
    "my_ax.contour( X, Y, Z, 2, alpha = 1, colors = ('blue','green','red'))\n",
    "\n",
    "# Add axis and title\n",
    "my_ax.set_xlabel('Petal Length')\n",
    "my_ax.set_ylabel('Petal Width')\n",
    "my_ax.set_title('LDA Decision Boundaries with Test Data');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quadratic Discriminant Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# QDA Classifier\n",
    "mod_qda_all = QuadraticDiscriminantAnalysis()\n",
    "y_pred = mod_qda_all.fit(X_train, y_train).predict(X_test)\n",
    "print('The accuracy of the QDA Classifier is',\"{:.3f}\".format(metrics.accuracy_score(y_pred,y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# QDA Classifier with two predictors\n",
    "mod_qda = QuadraticDiscriminantAnalysis()\n",
    "y_pred = mod_qda.fit(X_train[selected_predictors], y_train).predict(X_test[selected_predictors])\n",
    "print('The accuracy of the QDA Classifier with two predictors is',\"{:.3f}\".format(metrics.accuracy_score(y_pred,y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# QDA with 2 predictors\n",
    "mod_qda_1 = QuadraticDiscriminantAnalysis()\n",
    "y_pred = mod_qda_1.fit(X_train.iloc[:,2:4], y_train_en).predict(X_test.iloc[:,2:4])\n",
    "\n",
    "N = 300\n",
    "X = np.linspace(0, 7, N)\n",
    "Y = np.linspace(0, 3, N)\n",
    "X, Y = np.meshgrid(X, Y)\n",
    "\n",
    "g = sns.FacetGrid(test, hue=\"species\", height=5, palette = 'colorblind').map(plt.scatter,\"petal_length\", \"petal_width\", ).add_legend()\n",
    "my_ax = g.ax\n",
    "\n",
    "zz = np.array([mod_qda_1.predict(np.array([[xx,yy]])) for xx, yy in zip(np.ravel(X), np.ravel(Y)) ] )\n",
    "Z = zz.reshape(X.shape)\n",
    "\n",
    "#Plot the filled and boundary contours\n",
    "my_ax.contourf( X, Y, Z, 2, alpha = .1, colors = ('blue','green','red'))\n",
    "my_ax.contour( X, Y, Z, 2, alpha = 1, colors = ('blue','green','red'))\n",
    "\n",
    "# Addd axis and title\n",
    "my_ax.set_xlabel('Petal Length')\n",
    "my_ax.set_ylabel('Petal Width')\n",
    "my_ax.set_title('QDA Decision Boundaries with Test Data');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-Neighbors Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KNN, first try 5\n",
    "mod_5nn=KNeighborsClassifier(n_neighbors=5) \n",
    "mod_5nn.fit(X_train,y_train)\n",
    "prediction=mod_5nn.predict(X_test)\n",
    "print('The accuracy of the 5NN Classifier is',\"{:.3f}\".format(metrics.accuracy_score(prediction,y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try different k\n",
    "acc_s = pd.Series(dtype = 'float')\n",
    "for i in list(range(1,11)):\n",
    "    mod_knn=KNeighborsClassifier(n_neighbors=i) \n",
    "    mod_knn.fit(X_train,y_train)\n",
    "    prediction=mod_knn.predict(X_test)\n",
    "    acc_s = acc_s.append(pd.Series(metrics.accuracy_score(prediction,y_test)))\n",
    "    \n",
    "plt.plot(list(range(1,11)), acc_s)\n",
    "plt.suptitle(\"Test Accuracy vs K\")\n",
    "plt.xticks(list(range(1,11)))\n",
    "plt.ylim(0.9,0.98);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVC with linear kernel\n",
    "# for SVC, may be impractical beyond tens of thousands of samples\n",
    "linear_svc = SVC(kernel='linear').fit(X_train, y_train)\n",
    "prediction=linear_svc.predict(X_test)\n",
    "print('The accuracy of the linear SVC is',\"{:.3f}\".format(metrics.accuracy_score(prediction,y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVC with polynomial kernel\n",
    "poly_svc = SVC(kernel='poly', degree = 4).fit(X_train, y_train)\n",
    "prediction=poly_svc.predict(X_test)\n",
    "print('The accuracy of the Poly SVC is',\"{:.3f}\".format(metrics.accuracy_score(prediction,y_test)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
